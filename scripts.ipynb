{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 1. INSTALASI PACKAGES\n",
    "# ===============================================\n",
    "\n",
    "# Install required packages\n",
    "%pip install nltk PySastrawi requests beautifulsoup4 textblob wordcloud matplotlib seaborn scipy\n",
    "\n",
    "print(\"âœ… Packages berhasil diinstall!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efe36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 2. IMPORT LIBRARIES\n",
    "# ===============================================\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Utilities\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis, shapiro\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Set warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… Semua library berhasil diimport!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 2. DATA LOADING DAN PREPROCESSING DASAR\n",
    "# ===============================================\n",
    "\n",
    "# Data review redBus yang telah dianalisis dari Google Play Store\n",
    "redbus_reviews = [\n",
    "    {\n",
    "        \"review\": \"Our first trip was very good, and the booking went smooth. However, when I'm trying to use my 'referral code' in my friends' devices, it's just not working, showing 'something seems to be wrong'. I tried to use the 'chat with us' in the app, but the 'Help' section is not even opening, showing some webpage error. Please fix it soon.\",\n",
    "        \"rating\": 3,\n",
    "        \"sentiment\": \"mixed\"\n",
    "    },\n",
    "    {\n",
    "        \"review\": \"I had a medical emergency so not able to travel and tried for cancellation but directly redbus informed that I can't cancel my ticket and even I tried to reschedule as I have to travel in coming days but then also it's not possible. I don't understand if you can't provide any of this options then what services you provide and it's not at all expected. My experience is very worst and has occurred loss of 2500.\",\n",
    "        \"rating\": 1,\n",
    "        \"sentiment\": \"negative\"\n",
    "    },\n",
    "    {\n",
    "        \"review\": \"very bad algorithm, I went upto the payment procedure but due to technical issues the payment failed. next time the payment increase, I totally shocked. 2nd time also I checked the price after closing the app, again the price increase. very bad experience so I did not book the ticket. now I am going to uninstall the app. i know this will not impact you. but I don't want your app on my phone. so ta ta bye bye\",\n",
    "        \"rating\": 1,\n",
    "        \"sentiment\": \"negative\"\n",
    "    },\n",
    "    {\n",
    "        \"review\": \"Excellent app! Easy to use, great interface, and booking is very smooth. Love the new features like train booking and metro tickets. Highly recommended!\",\n",
    "        \"rating\": 5,\n",
    "        \"sentiment\": \"positive\"\n",
    "    },\n",
    "    {\n",
    "        \"review\": \"Good app overall but sometimes the bus tracking is not accurate. Customer service is helpful though. Would give 4 stars if tracking was better.\",\n",
    "        \"rating\": 4,\n",
    "        \"sentiment\": \"positive\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Konversi ke DataFrame untuk analisis\n",
    "df = pd.DataFrame(redbus_reviews)\n",
    "\n",
    "# Inisialisasi stemmer Sastrawi\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# Tambahkan kolom untuk analisis\n",
    "df['review_length'] = df['review'].str.len()\n",
    "df['word_count'] = df['review'].apply(lambda x: len(x.split()))\n",
    "df['sentence_count'] = df['review'].apply(lambda x: len(x.split('.')))\n",
    "\n",
    "# Buat kolom numerik untuk sentimen\n",
    "sentiment_map = {'positive': 1, 'negative': -1, 'mixed': 0}\n",
    "df['sentiment_numeric'] = df['sentiment'].map(sentiment_map)\n",
    "\n",
    "print(\"âœ… Data berhasil dimuat!\")\n",
    "print(f\"ðŸ“Š Dataset berisi {len(df)} review\")\n",
    "print(f\"ðŸ“‹ Kolom yang tersedia: {list(df.columns)}\")\n",
    "print(f\"ðŸ“ˆ Shape dataset: {df.shape}\")\n",
    "\n",
    "# Tampilkan preview data\n",
    "print(\"\\nðŸ“‹ Preview Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac746507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 3. ANALISIS STATISTIK DASAR\n",
    "# ===============================================\n",
    "\n",
    "print(\"=== ANALISIS STATISTIK DASAR ===\\n\")\n",
    "\n",
    "# 1. INFORMASI DASAR DATASET\n",
    "print(\"1. INFORMASI DASAR DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape dataset: {df.shape}\")\n",
    "print(f\"Jumlah baris: {df.shape[0]}\")\n",
    "print(f\"Jumlah kolom: {df.shape[1]}\")\n",
    "print(f\"Kolom yang tersedia: {list(df.columns)}\")\n",
    "print(f\"Tipe data:\\n{df.dtypes}\")\n",
    "print(f\"Memori yang digunakan: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "# 2. STATISTIK DESKRIPTIF\n",
    "print(\"\\n2. STATISTIK DESKRIPTIF\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Statistik untuk kolom numerik:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 3. ANALISIS MISSING VALUES\n",
    "print(\"\\n3. ANALISIS MISSING VALUES\")\n",
    "print(\"=\" * 50)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_df)\n",
    "\n",
    "# 4. ANALISIS DISTRIBUSI RATING\n",
    "print(\"\\n4. ANALISIS DISTRIBUSI RATING\")\n",
    "print(\"=\" * 50)\n",
    "rating_stats = df['rating'].describe()\n",
    "print(\"Statistik Rating:\")\n",
    "print(f\"Mean: {rating_stats['mean']:.2f}\")\n",
    "print(f\"Median: {rating_stats['50%']:.2f}\")\n",
    "print(f\"Mode: {df['rating'].mode().iloc[0]}\")\n",
    "print(f\"Std Dev: {rating_stats['std']:.2f}\")\n",
    "print(f\"Min: {rating_stats['min']:.2f}\")\n",
    "print(f\"Max: {rating_stats['max']:.2f}\")\n",
    "print(f\"Range: {rating_stats['max'] - rating_stats['min']:.2f}\")\n",
    "\n",
    "# Distribusi rating\n",
    "rating_dist = df['rating'].value_counts().sort_index()\n",
    "print(f\"\\nDistribusi Rating:\")\n",
    "for rating, count in rating_dist.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"Rating {rating}: {count} review ({percentage:.1f}%)\")\n",
    "\n",
    "# 5. ANALISIS SENTIMEN\n",
    "print(\"\\n5. ANALISIS SENTIMEN\")\n",
    "print(\"=\" * 50)\n",
    "sentiment_dist = df['sentiment'].value_counts()\n",
    "print(\"Distribusi Sentimen:\")\n",
    "for sentiment, count in sentiment_dist.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{sentiment.capitalize()}: {count} review ({percentage:.1f}%)\")\n",
    "\n",
    "# 6. ANALISIS PANJANG REVIEW\n",
    "print(\"\\n6. ANALISIS PANJANG REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Statistik Panjang Review:\")\n",
    "print(f\"Rata-rata karakter: {df['review_length'].mean():.1f}\")\n",
    "print(f\"Rata-rata kata: {df['word_count'].mean():.1f}\")\n",
    "print(f\"Rata-rata kalimat: {df['sentence_count'].mean():.1f}\")\n",
    "print(f\"Review terpanjang: {df['review_length'].max()} karakter\")\n",
    "print(f\"Review terpendek: {df['review_length'].min()} karakter\")\n",
    "\n",
    "# 7. KORELASI ANTAR VARIABEL\n",
    "print(\"\\n7. KORELASI ANTAR VARIABEL\")\n",
    "print(\"=\" * 50)\n",
    "correlation_matrix = df[['rating', 'review_length', 'word_count', 'sentence_count', 'sentiment_numeric']].corr()\n",
    "print(\"Matriks Korelasi:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "print(\"\\nâœ… Analisis statistik dasar selesai!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 4. VISUALISASI DATA\n",
    "# ===============================================\n",
    "\n",
    "print(\"=== VISUALISASI DATA ===\\n\")\n",
    "\n",
    "# 1. VISUALISASI DISTRIBUSI RATING\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Exploratory Data Analysis - redBus Reviews', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1.1 Distribusi Rating (Bar Chart)\n",
    "axes[0, 0].bar(df['rating'].value_counts().sort_index().index, \n",
    "               df['rating'].value_counts().sort_index().values,\n",
    "               color=['#ff4444', '#ff8800', '#ffaa00', '#88cc00', '#00cc44'])\n",
    "axes[0, 0].set_title('Distribusi Rating', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Rating')\n",
    "axes[0, 0].set_ylabel('Jumlah Review')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 1.2 Distribusi Sentimen (Pie Chart)\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\n",
    "axes[0, 1].pie(sentiment_counts.values, labels=sentiment_counts.index, \n",
    "               autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "axes[0, 1].set_title('Distribusi Sentimen', fontweight='bold')\n",
    "\n",
    "# 1.3 Histogram Panjang Review\n",
    "axes[0, 2].hist(df['review_length'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 2].set_title('Distribusi Panjang Review (Karakter)', fontweight='bold')\n",
    "axes[0, 2].set_xlabel('Jumlah Karakter')\n",
    "axes[0, 2].set_ylabel('Frekuensi')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 1.4 Box Plot Rating vs Panjang Review\n",
    "sns.boxplot(data=df, x='rating', y='review_length', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Rating vs Panjang Review', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Rating')\n",
    "axes[1, 0].set_ylabel('Panjang Review (Karakter)')\n",
    "\n",
    "# 1.5 Scatter Plot: Rating vs Word Count\n",
    "axes[1, 1].scatter(df['rating'], df['word_count'], alpha=0.7, color='purple')\n",
    "axes[1, 1].set_title('Rating vs Jumlah Kata', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Rating')\n",
    "axes[1, 1].set_ylabel('Jumlah Kata')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 1.6 Heatmap Korelasi\n",
    "correlation_data = df[['rating', 'review_length', 'word_count', 'sentence_count', 'sentiment_numeric']]\n",
    "correlation_matrix = correlation_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Heatmap Korelasi', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. VISUALISASI LANJUTAN\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Analisis Lanjutan - redBus Reviews', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 2.1 Violin Plot: Sentimen vs Panjang Review\n",
    "sns.violinplot(data=df, x='sentiment', y='review_length', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribusi Panjang Review per Sentimen', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Sentimen')\n",
    "axes[0, 0].set_ylabel('Panjang Review (Karakter)')\n",
    "\n",
    "# 2.2 Bar Plot: Rata-rata Rating per Sentimen\n",
    "sentiment_rating = df.groupby('sentiment')['rating'].mean().sort_values(ascending=False)\n",
    "axes[0, 1].bar(sentiment_rating.index, sentiment_rating.values, \n",
    "               color=['#ff6b6b', '#4ecdc4', '#45b7d1'])\n",
    "axes[0, 1].set_title('Rata-rata Rating per Sentimen', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Sentimen')\n",
    "axes[0, 1].set_ylabel('Rata-rata Rating')\n",
    "axes[0, 1].set_ylim(0, 5)\n",
    "\n",
    "# 2.3 Histogram Word Count\n",
    "axes[1, 0].hist(df['word_count'], bins=12, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Distribusi Jumlah Kata', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Jumlah Kata')\n",
    "axes[1, 0].set_ylabel('Frekuensi')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2.4 Scatter Plot: Review Length vs Word Count dengan Color Coding Rating\n",
    "scatter = axes[1, 1].scatter(df['review_length'], df['word_count'], \n",
    "                            c=df['rating'], cmap='viridis', alpha=0.7)\n",
    "axes[1, 1].set_title('Panjang Review vs Jumlah Kata (Color: Rating)', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Panjang Review (Karakter)')\n",
    "axes[1, 1].set_ylabel('Jumlah Kata')\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualisasi data selesai!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0285ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 5. WORD CLOUD ANALYSIS\n",
    "# ===============================================\n",
    "\n",
    "print(\"=== WORD CLOUD ANALYSIS ===\\n\")\n",
    "\n",
    "# 1. WORD CLOUD untuk semua review\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Word Cloud untuk semua review\n",
    "plt.subplot(1, 3, 1)\n",
    "all_text = ' '.join(df['review'])\n",
    "wordcloud_all = WordCloud(width=400, height=300, background_color='white').generate(all_text)\n",
    "plt.imshow(wordcloud_all, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Semua Review', fontweight='bold')\n",
    "\n",
    "# Word Cloud untuk review positif\n",
    "plt.subplot(1, 3, 2)\n",
    "positive_text = ' '.join(df[df['sentiment'] == 'positive']['review'])\n",
    "if positive_text:\n",
    "    wordcloud_positive = WordCloud(width=400, height=300, background_color='white').generate(positive_text)\n",
    "    plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud - Review Positif', fontweight='bold')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Tidak ada data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud - Review Positif', fontweight='bold')\n",
    "\n",
    "# Word Cloud untuk review negatif\n",
    "plt.subplot(1, 3, 3)\n",
    "negative_text = ' '.join(df[df['sentiment'] == 'negative']['review'])\n",
    "if negative_text:\n",
    "    wordcloud_negative = WordCloud(width=400, height=300, background_color='white').generate(negative_text)\n",
    "    plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud - Review Negatif', fontweight='bold')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Tidak ada data', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud - Review Negatif', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. ANALISIS KATA KUNCI\n",
    "print(\"2. ANALISIS KATA KUNCI\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Gabungkan semua review\n",
    "all_text = ' '.join(df['review'].str.lower())\n",
    "# Tokenisasi sederhana\n",
    "words = all_text.split()\n",
    "# Filter kata yang panjangnya > 3 karakter\n",
    "meaningful_words = [word for word in words if len(word) > 3 and word.isalpha()]\n",
    "word_freq = Counter(meaningful_words)\n",
    "\n",
    "print(\"10 Kata Paling Sering Muncul:\")\n",
    "for word, count in word_freq.most_common(10):\n",
    "    print(f\"{word}: {count} kali\")\n",
    "\n",
    "# 3. ANALISIS KATA KUNCI POSITIF DAN NEGATIF\n",
    "print(\"\\n3. ANALISIS KATA KUNCI POSITIF DAN NEGATIF\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analisis kata kunci positif dan negatif\n",
    "positive_reviews = df[df['rating'] >= 4]\n",
    "negative_reviews = df[df['rating'] <= 2]\n",
    "\n",
    "positive_tokens = []\n",
    "negative_tokens = []\n",
    "\n",
    "for review in positive_reviews['review']:\n",
    "    positive_tokens.extend(word_tokenize(review.lower()))\n",
    "\n",
    "for review in negative_reviews['review']:\n",
    "    negative_tokens.extend(word_tokenize(review.lower()))\n",
    "\n",
    "print(\"Kata Kunci Positif:\")\n",
    "for word, count in Counter(positive_tokens).most_common(10):\n",
    "    print(f\"  {word}: {count} kali\")\n",
    "\n",
    "print(\"\\nKata Kunci Negatif:\")\n",
    "for word, count in Counter(negative_tokens).most_common(10):\n",
    "    print(f\"  {word}: {count} kali\")\n",
    "\n",
    "print(\"\\nâœ… Word cloud analysis selesai!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 6. ANALISIS KUALITAS DATA\n",
    "# ===============================================\n",
    "\n",
    "print(\"=== ANALISIS KUALITAS DATA ===\\n\")\n",
    "\n",
    "# 1. ANALISIS MISSING VALUES DETAIL\n",
    "print(\"1. ANALISIS MISSING VALUES DETAIL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cek missing values per kolom\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Kolom': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes,\n",
    "    'Unique_Values': df.nunique()\n",
    "})\n",
    "\n",
    "print(\"Ringkasan Missing Values:\")\n",
    "print(missing_analysis)\n",
    "\n",
    "# Cek missing values per baris\n",
    "df['missing_per_row'] = df.isnull().sum(axis=1)\n",
    "print(f\"\\nBaris dengan missing values: {df['missing_per_row'].sum()}\")\n",
    "print(f\"Persentase baris dengan missing values: {(df['missing_per_row'] > 0).sum() / len(df) * 100:.2f}%\")\n",
    "\n",
    "# 2. ANALISIS KUALITAS DATA TEXT\n",
    "print(\"\\n2. ANALISIS KUALITAS DATA TEXT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 2.1 Analisis karakter khusus dan simbol\n",
    "def analyze_text_quality(text):\n",
    "    \"\"\"Analisis kualitas teks review\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {\n",
    "            'length': 0,\n",
    "            'word_count': 0,\n",
    "            'has_special_chars': False,\n",
    "            'has_numbers': False,\n",
    "            'has_uppercase': False,\n",
    "            'has_punctuation': False,\n",
    "            'is_empty': True\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'length': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'has_special_chars': bool(re.search(r'[^a-zA-Z0-9\\s.,!?]', text)),\n",
    "        'has_numbers': bool(re.search(r'\\d', text)),\n",
    "        'has_uppercase': bool(re.search(r'[A-Z]', text)),\n",
    "        'has_punctuation': bool(re.search(r'[.,!?]', text)),\n",
    "        'is_empty': len(text.strip()) == 0\n",
    "    }\n",
    "\n",
    "# Analisis kualitas teks untuk setiap review\n",
    "text_quality = df['review'].apply(analyze_text_quality)\n",
    "text_quality_df = pd.DataFrame(list(text_quality))\n",
    "\n",
    "print(\"Statistik Kualitas Teks:\")\n",
    "print(f\"Review kosong: {text_quality_df['is_empty'].sum()}\")\n",
    "print(f\"Review dengan karakter khusus: {text_quality_df['has_special_chars'].sum()}\")\n",
    "print(f\"Review dengan angka: {text_quality_df['has_numbers'].sum()}\")\n",
    "print(f\"Review dengan huruf kapital: {text_quality_df['has_uppercase'].sum()}\")\n",
    "print(f\"Review dengan tanda baca: {text_quality_df['has_punctuation'].sum()}\")\n",
    "\n",
    "# 2.2 Analisis panjang review yang ekstrem\n",
    "print(f\"\\nReview terpendek: {text_quality_df['length'].min()} karakter\")\n",
    "print(f\"Review terpanjang: {text_quality_df['length'].max()} karakter\")\n",
    "print(f\"Rata-rata panjang: {text_quality_df['length'].mean():.1f} karakter\")\n",
    "\n",
    "# Identifikasi review yang sangat pendek atau sangat panjang\n",
    "very_short = text_quality_df['length'] < 10\n",
    "very_long = text_quality_df['length'] > 500\n",
    "print(f\"Review sangat pendek (<10 karakter): {very_short.sum()}\")\n",
    "print(f\"Review sangat panjang (>500 karakter): {very_long.sum()}\")\n",
    "\n",
    "# 3. ANALISIS KONSISTENSI DATA\n",
    "print(\"\\n3. ANALISIS KONSISTENSI DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 3.1 Konsistensi rating dan sentimen\n",
    "print(\"Analisis Konsistensi Rating vs Sentimen:\")\n",
    "for rating in sorted(df['rating'].unique()):\n",
    "    rating_data = df[df['rating'] == rating]\n",
    "    sentiment_dist = rating_data['sentiment'].value_counts()\n",
    "    print(f\"\\nRating {rating}:\")\n",
    "    for sentiment, count in sentiment_dist.items():\n",
    "        percentage = (count / len(rating_data)) * 100\n",
    "        print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# 3.2 Identifikasi inkonsistensi\n",
    "inconsistencies = []\n",
    "for idx, row in df.iterrows():\n",
    "    rating = row['rating']\n",
    "    sentiment = row['sentiment']\n",
    "    \n",
    "    # Logika konsistensi: rating tinggi = positive, rating rendah = negative\n",
    "    if rating >= 4 and sentiment == 'negative':\n",
    "        inconsistencies.append(f\"Row {idx}: Rating {rating} tapi sentimen {sentiment}\")\n",
    "    elif rating <= 2 and sentiment == 'positive':\n",
    "        inconsistencies.append(f\"Row {idx}: Rating {rating} tapi sentimen {sentiment}\")\n",
    "\n",
    "print(f\"\\nInkonsistensi yang ditemukan: {len(inconsistencies)}\")\n",
    "for inconsistency in inconsistencies[:5]:  # Tampilkan 5 pertama\n",
    "    print(f\"  - {inconsistency}\")\n",
    "\n",
    "# 4. ANALISIS OUTLIERS DETAIL\n",
    "print(\"\\n4. ANALISIS OUTLIERS DETAIL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 4.1 Outliers menggunakan IQR method\n",
    "def detect_outliers_iqr(data, column_name):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Analisis outliers untuk berbagai metrik\n",
    "outlier_analysis = {}\n",
    "metrics = ['review_length', 'word_count', 'sentence_count']\n",
    "\n",
    "for metric in metrics:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df[metric], metric)\n",
    "    outlier_analysis[metric] = {\n",
    "        'outliers': outliers,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper,\n",
    "        'count': len(outliers)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Outliers: {len(outliers)}\")\n",
    "    print(f\"  Lower bound: {lower:.1f}\")\n",
    "    print(f\"  Upper bound: {upper:.1f}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  Outlier values: {outliers.tolist()}\")\n",
    "\n",
    "# 4.2 Outliers menggunakan Z-score method\n",
    "print(f\"\\nOutliers menggunakan Z-score (|z| > 2):\")\n",
    "for metric in metrics:\n",
    "    z_scores = np.abs(stats.zscore(df[metric]))\n",
    "    outliers_z = df[z_scores > 2]\n",
    "    print(f\"  {metric}: {len(outliers_z)} outliers\")\n",
    "\n",
    "# 5. ANALISIS DUPLICATE DATA\n",
    "print(\"\\n5. ANALISIS DUPLICATE DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cek duplicate berdasarkan review text\n",
    "duplicate_reviews = df.duplicated(subset=['review'], keep=False)\n",
    "print(f\"Review duplikat: {duplicate_reviews.sum()}\")\n",
    "\n",
    "if duplicate_reviews.sum() > 0:\n",
    "    print(\"Review yang duplikat:\")\n",
    "    duplicate_data = df[duplicate_reviews][['review', 'rating', 'sentiment']]\n",
    "    print(duplicate_data)\n",
    "\n",
    "# Cek duplicate berdasarkan semua kolom\n",
    "duplicate_all = df.duplicated(keep=False)\n",
    "print(f\"Baris duplikat (semua kolom): {duplicate_all.sum()}\")\n",
    "\n",
    "print(\"\\nâœ… Analisis kualitas data selesai!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50760b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# ANALISIS KUALITAS DATA DAN MISSING VALUES\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== ANALISIS KUALITAS DATA ===\\n\")\n",
    "\n",
    "# 1. ANALISIS MISSING VALUES DETAIL\n",
    "print(\"1. ANALISIS MISSING VALUES DETAIL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cek missing values per kolom\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Kolom': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes,\n",
    "    'Unique_Values': df.nunique()\n",
    "})\n",
    "\n",
    "print(\"Ringkasan Missing Values:\")\n",
    "print(missing_analysis)\n",
    "\n",
    "# Cek missing values per baris\n",
    "df['missing_per_row'] = df.isnull().sum(axis=1)\n",
    "print(f\"\\nBaris dengan missing values: {df['missing_per_row'].sum()}\")\n",
    "print(f\"Persentase baris dengan missing values: {(df['missing_per_row'] > 0).sum() / len(df) * 100:.2f}%\")\n",
    "\n",
    "# 2. ANALISIS KUALITAS DATA TEXT\n",
    "print(\"\\n2. ANALISIS KUALITAS DATA TEXT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 2.1 Analisis karakter khusus dan simbol\n",
    "def analyze_text_quality(text):\n",
    "    \"\"\"Analisis kualitas teks review\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {\n",
    "            'length': 0,\n",
    "            'word_count': 0,\n",
    "            'has_special_chars': False,\n",
    "            'has_numbers': False,\n",
    "            'has_uppercase': False,\n",
    "            'has_punctuation': False,\n",
    "            'is_empty': True\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'length': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'has_special_chars': bool(re.search(r'[^a-zA-Z0-9\\s.,!?]', text)),\n",
    "        'has_numbers': bool(re.search(r'\\d', text)),\n",
    "        'has_uppercase': bool(re.search(r'[A-Z]', text)),\n",
    "        'has_punctuation': bool(re.search(r'[.,!?]', text)),\n",
    "        'is_empty': len(text.strip()) == 0\n",
    "    }\n",
    "\n",
    "# Analisis kualitas teks untuk setiap review\n",
    "text_quality = df['review'].apply(analyze_text_quality)\n",
    "text_quality_df = pd.DataFrame(list(text_quality))\n",
    "\n",
    "print(\"Statistik Kualitas Teks:\")\n",
    "print(f\"Review kosong: {text_quality_df['is_empty'].sum()}\")\n",
    "print(f\"Review dengan karakter khusus: {text_quality_df['has_special_chars'].sum()}\")\n",
    "print(f\"Review dengan angka: {text_quality_df['has_numbers'].sum()}\")\n",
    "print(f\"Review dengan huruf kapital: {text_quality_df['has_uppercase'].sum()}\")\n",
    "print(f\"Review dengan tanda baca: {text_quality_df['has_punctuation'].sum()}\")\n",
    "\n",
    "# 2.2 Analisis panjang review yang ekstrem\n",
    "print(f\"\\nReview terpendek: {text_quality_df['length'].min()} karakter\")\n",
    "print(f\"Review terpanjang: {text_quality_df['length'].max()} karakter\")\n",
    "print(f\"Rata-rata panjang: {text_quality_df['length'].mean():.1f} karakter\")\n",
    "\n",
    "# Identifikasi review yang sangat pendek atau sangat panjang\n",
    "very_short = text_quality_df['length'] < 10\n",
    "very_long = text_quality_df['length'] > 500\n",
    "print(f\"Review sangat pendek (<10 karakter): {very_short.sum()}\")\n",
    "print(f\"Review sangat panjang (>500 karakter): {very_long.sum()}\")\n",
    "\n",
    "# 3. ANALISIS KONSISTENSI DATA\n",
    "print(\"\\n3. ANALISIS KONSISTENSI DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 3.1 Konsistensi rating dan sentimen\n",
    "print(\"Analisis Konsistensi Rating vs Sentimen:\")\n",
    "for rating in sorted(df['rating'].unique()):\n",
    "    rating_data = df[df['rating'] == rating]\n",
    "    sentiment_dist = rating_data['sentiment'].value_counts()\n",
    "    print(f\"\\nRating {rating}:\")\n",
    "    for sentiment, count in sentiment_dist.items():\n",
    "        percentage = (count / len(rating_data)) * 100\n",
    "        print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# 3.2 Identifikasi inkonsistensi\n",
    "inconsistencies = []\n",
    "for idx, row in df.iterrows():\n",
    "    rating = row['rating']\n",
    "    sentiment = row['sentiment']\n",
    "    \n",
    "    # Logika konsistensi: rating tinggi = positive, rating rendah = negative\n",
    "    if rating >= 4 and sentiment == 'negative':\n",
    "        inconsistencies.append(f\"Row {idx}: Rating {rating} tapi sentimen {sentiment}\")\n",
    "    elif rating <= 2 and sentiment == 'positive':\n",
    "        inconsistencies.append(f\"Row {idx}: Rating {rating} tapi sentimen {sentiment}\")\n",
    "\n",
    "print(f\"\\nInkonsistensi yang ditemukan: {len(inconsistencies)}\")\n",
    "for inconsistency in inconsistencies[:5]:  # Tampilkan 5 pertama\n",
    "    print(f\"  - {inconsistency}\")\n",
    "\n",
    "# 4. ANALISIS OUTLIERS DETAIL\n",
    "print(\"\\n4. ANALISIS OUTLIERS DETAIL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 4.1 Outliers menggunakan IQR method\n",
    "def detect_outliers_iqr(data, column_name):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Analisis outliers untuk berbagai metrik\n",
    "outlier_analysis = {}\n",
    "metrics = ['review_length', 'word_count', 'sentence_count']\n",
    "\n",
    "for metric in metrics:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df[metric], metric)\n",
    "    outlier_analysis[metric] = {\n",
    "        'outliers': outliers,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper,\n",
    "        'count': len(outliers)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    print(f\"  Outliers: {len(outliers)}\")\n",
    "    print(f\"  Lower bound: {lower:.1f}\")\n",
    "    print(f\"  Upper bound: {upper:.1f}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  Outlier values: {outliers.tolist()}\")\n",
    "\n",
    "# 4.2 Outliers menggunakan Z-score method\n",
    "from scipy import stats\n",
    "\n",
    "print(f\"\\nOutliers menggunakan Z-score (|z| > 2):\")\n",
    "for metric in metrics:\n",
    "    z_scores = np.abs(stats.zscore(df[metric]))\n",
    "    outliers_z = df[z_scores > 2]\n",
    "    print(f\"  {metric}: {len(outliers_z)} outliers\")\n",
    "\n",
    "# 5. ANALISIS DUPLICATE DATA\n",
    "print(\"\\n5. ANALISIS DUPLICATE DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cek duplicate berdasarkan review text\n",
    "duplicate_reviews = df.duplicated(subset=['review'], keep=False)\n",
    "print(f\"Review duplikat: {duplicate_reviews.sum()}\")\n",
    "\n",
    "if duplicate_reviews.sum() > 0:\n",
    "    print(\"Review yang duplikat:\")\n",
    "    duplicate_data = df[duplicate_reviews][['review', 'rating', 'sentiment']]\n",
    "    print(duplicate_data)\n",
    "\n",
    "# Cek duplicate berdasarkan semua kolom\n",
    "duplicate_all = df.duplicated(keep=False)\n",
    "print(f\"Baris duplikat (semua kolom): {duplicate_all.sum()}\")\n",
    "\n",
    "# 6. ANALISIS DATA DISTRIBUSI\n",
    "print(\"\\n6. ANALISIS DATA DISTRIBUSI\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 6.1 Skewness dan Kurtosis\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "print(\"Skewness dan Kurtosis:\")\n",
    "for metric in metrics:\n",
    "    skewness = skew(df[metric])\n",
    "    kurt = kurtosis(df[metric])\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  Skewness: {skewness:.3f} ({'Right skewed' if skewness > 0 else 'Left skewed' if skewness < 0 else 'Symmetric'})\")\n",
    "    print(f\"  Kurtosis: {kurt:.3f} ({'Heavy tailed' if kurt > 0 else 'Light tailed' if kurt < 0 else 'Normal'})\")\n",
    "\n",
    "# 6.2 Normalitas data\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "print(f\"\\nUji Normalitas (Shapiro-Wilk):\")\n",
    "for metric in metrics:\n",
    "    if len(df[metric]) <= 5000:  # Shapiro-Wilk works best with small samples\n",
    "        stat, p_value = shapiro(df[metric])\n",
    "        print(f\"{metric}: p-value = {p_value:.6f} ({'Normal' if p_value > 0.05 else 'Not normal'})\")\n",
    "    else:\n",
    "        print(f\"{metric}: Sample too large for Shapiro-Wilk test\")\n",
    "\n",
    "# 7. REKOMENDASI PERBAIKAN DATA\n",
    "print(\"\\n7. REKOMENDASI PERBAIKAN DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Rekomendasi berdasarkan missing values\n",
    "if missing_analysis['Missing_Count'].sum() > 0:\n",
    "    recommendations.append(\"Terdapat missing values yang perlu ditangani\")\n",
    "\n",
    "# Rekomendasi berdasarkan outliers\n",
    "total_outliers = sum([analysis['count'] for analysis in outlier_analysis.values()])\n",
    "if total_outliers > 0:\n",
    "    recommendations.append(f\"Terdapat {total_outliers} outliers yang perlu dievaluasi\")\n",
    "\n",
    "# Rekomendasi berdasarkan inkonsistensi\n",
    "if len(inconsistencies) > 0:\n",
    "    recommendations.append(f\"Terdapat {len(inconsistencies)} inkonsistensi rating-sentimen\")\n",
    "\n",
    "# Rekomendasi berdasarkan duplicate\n",
    "if duplicate_reviews.sum() > 0:\n",
    "    recommendations.append(f\"Terdapat {duplicate_reviews.sum()} review duplikat\")\n",
    "\n",
    "# Rekomendasi berdasarkan kualitas teks\n",
    "if text_quality_df['is_empty'].sum() > 0:\n",
    "    recommendations.append(\"Terdapat review kosong yang perlu dihapus\")\n",
    "\n",
    "if very_short.sum() > 0:\n",
    "    recommendations.append(f\"Terdapat {very_short.sum()} review sangat pendek yang perlu dievaluasi\")\n",
    "\n",
    "print(\"Rekomendasi Perbaikan Data:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "if not recommendations:\n",
    "    print(\"Data dalam kondisi baik, siap untuk preprocessing!\")\n",
    "\n",
    "print(\"\\n=== ANALISIS KUALITAS DATA SELESAI ===\")\n",
    "print(\"Data telah dianalisis secara menyeluruh untuk kualitas dan konsistensi!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# SUMMARY REPORT EXPLORATORY DATA ANALYSIS\n",
    "# ===============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== SUMMARY REPORT EDA - REDBUS REVIEWS ===\\n\")\n",
    "\n",
    "# Generate comprehensive EDA report\n",
    "def generate_eda_summary():\n",
    "    \"\"\"Generate comprehensive EDA summary report\"\"\"\n",
    "    \n",
    "    # 1. EXECUTIVE SUMMARY\n",
    "    print(\"1. EXECUTIVE SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Tanggal Analisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Dataset: redBus Reviews\")\n",
    "    print(f\"Total Records: {len(df)}\")\n",
    "    print(f\"Total Features: {len(df.columns)}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "    \n",
    "    # 2. DATA OVERVIEW\n",
    "    print(f\"\\n2. DATA OVERVIEW\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Dataset Structure:\")\n",
    "    print(f\"- Shape: {df.shape}\")\n",
    "    print(f\"- Columns: {list(df.columns)}\")\n",
    "    print(f\"- Data Types:\")\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        print(f\"  * {col}: {dtype}\")\n",
    "    \n",
    "    # 3. STATISTICAL SUMMARY\n",
    "    print(f\"\\n3. STATISTICAL SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Rating statistics\n",
    "    rating_stats = df['rating'].describe()\n",
    "    print(\"Rating Statistics:\")\n",
    "    print(f\"- Mean: {rating_stats['mean']:.2f}\")\n",
    "    print(f\"- Median: {rating_stats['50%']:.2f}\")\n",
    "    print(f\"- Std Dev: {rating_stats['std']:.2f}\")\n",
    "    print(f\"- Min: {rating_stats['min']:.2f}\")\n",
    "    print(f\"- Max: {rating_stats['max']:.2f}\")\n",
    "    \n",
    "    # Review length statistics\n",
    "    print(f\"\\nReview Length Statistics:\")\n",
    "    print(f\"- Mean characters: {df['review_length'].mean():.1f}\")\n",
    "    print(f\"- Mean words: {df['word_count'].mean():.1f}\")\n",
    "    print(f\"- Mean sentences: {df['sentence_count'].mean():.1f}\")\n",
    "    \n",
    "    # 4. DATA DISTRIBUTION\n",
    "    print(f\"\\n4. DATA DISTRIBUTION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Rating distribution\n",
    "    print(\"Rating Distribution:\")\n",
    "    rating_dist = df['rating'].value_counts().sort_index()\n",
    "    for rating, count in rating_dist.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"- Rating {rating}: {count} reviews ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    print(f\"\\nSentiment Distribution:\")\n",
    "    sentiment_dist = df['sentiment'].value_counts()\n",
    "    for sentiment, count in sentiment_dist.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"- {sentiment.capitalize()}: {count} reviews ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 5. DATA QUALITY ASSESSMENT\n",
    "    print(f\"\\n5. DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Missing values\n",
    "    missing_count = df.isnull().sum().sum()\n",
    "    missing_percentage = (missing_count / (len(df) * len(df.columns))) * 100\n",
    "    print(f\"Missing Values:\")\n",
    "    print(f\"- Total missing: {missing_count}\")\n",
    "    print(f\"- Percentage: {missing_percentage:.2f}%\")\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    duplicate_percentage = (duplicate_count / len(df)) * 100\n",
    "    print(f\"\\nDuplicate Records:\")\n",
    "    print(f\"- Total duplicates: {duplicate_count}\")\n",
    "    print(f\"- Percentage: {duplicate_percentage:.2f}%\")\n",
    "    \n",
    "    # Data consistency\n",
    "    inconsistencies = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        rating = row['rating']\n",
    "        sentiment = row['sentiment']\n",
    "        if (rating >= 4 and sentiment == 'negative') or (rating <= 2 and sentiment == 'positive'):\n",
    "            inconsistencies += 1\n",
    "    \n",
    "    print(f\"\\nData Consistency:\")\n",
    "    print(f\"- Inconsistencies: {inconsistencies}\")\n",
    "    print(f\"- Consistency rate: {((len(df) - inconsistencies) / len(df)) * 100:.1f}%\")\n",
    "    \n",
    "    # 6. KEY INSIGHTS\n",
    "    print(f\"\\n6. KEY INSIGHTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Rating insights\n",
    "    high_rating = df[df['rating'] >= 4]\n",
    "    low_rating = df[df['rating'] <= 2]\n",
    "    \n",
    "    print(\"Rating Insights:\")\n",
    "    print(f\"- High ratings (4-5): {len(high_rating)} reviews ({len(high_rating)/len(df)*100:.1f}%)\")\n",
    "    print(f\"- Low ratings (1-2): {len(low_rating)} reviews ({len(low_rating)/len(df)*100:.1f}%)\")\n",
    "    print(f\"- Average rating: {df['rating'].mean():.2f}\")\n",
    "    \n",
    "    # Text insights\n",
    "    print(f\"\\nText Insights:\")\n",
    "    print(f\"- Average review length: {df['review_length'].mean():.1f} characters\")\n",
    "    print(f\"- Average word count: {df['word_count'].mean():.1f} words\")\n",
    "    print(f\"- Longest review: {df['review_length'].max()} characters\")\n",
    "    print(f\"- Shortest review: {df['review_length'].min()} characters\")\n",
    "    \n",
    "    # Correlation insights\n",
    "    rating_length_corr = df['rating'].corr(df['review_length'])\n",
    "    rating_words_corr = df['rating'].corr(df['word_count'])\n",
    "    \n",
    "    print(f\"\\nCorrelation Insights:\")\n",
    "    print(f\"- Rating vs Review Length: {rating_length_corr:.3f}\")\n",
    "    print(f\"- Rating vs Word Count: {rating_words_corr:.3f}\")\n",
    "    \n",
    "    # 7. OUTLIERS ANALYSIS\n",
    "    print(f\"\\n7. OUTLIERS ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # IQR method for outliers\n",
    "    def count_outliers_iqr(data):\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "        return len(outliers)\n",
    "    \n",
    "    review_length_outliers = count_outliers_iqr(df['review_length'])\n",
    "    word_count_outliers = count_outliers_iqr(df['word_count'])\n",
    "    \n",
    "    print(f\"Outliers (IQR method):\")\n",
    "    print(f\"- Review length outliers: {review_length_outliers}\")\n",
    "    print(f\"- Word count outliers: {word_count_outliers}\")\n",
    "    \n",
    "    # 8. RECOMMENDATIONS\n",
    "    print(f\"\\n8. RECOMMENDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Data quality recommendations\n",
    "    if missing_count > 0:\n",
    "        recommendations.append(\"Handle missing values before analysis\")\n",
    "    \n",
    "    if duplicate_count > 0:\n",
    "        recommendations.append(\"Remove or handle duplicate records\")\n",
    "    \n",
    "    if inconsistencies > 0:\n",
    "        recommendations.append(\"Review and correct rating-sentiment inconsistencies\")\n",
    "    \n",
    "    if review_length_outliers > 0 or word_count_outliers > 0:\n",
    "        recommendations.append(\"Evaluate outliers for data quality issues\")\n",
    "    \n",
    "    # Analysis recommendations\n",
    "    if len(df) < 100:\n",
    "        recommendations.append(\"Consider collecting more data for robust analysis\")\n",
    "    \n",
    "    if abs(rating_length_corr) < 0.3:\n",
    "        recommendations.append(\"Weak correlation between rating and text length - investigate further\")\n",
    "    \n",
    "    # Preprocessing recommendations\n",
    "    recommendations.append(\"Apply text preprocessing (tokenization, stemming, stop words removal)\")\n",
    "    recommendations.append(\"Consider feature engineering for text analysis\")\n",
    "    recommendations.append(\"Implement proper train-test split for modeling\")\n",
    "    \n",
    "    print(\"Data Preprocessing Recommendations:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    \n",
    "    # 9. NEXT STEPS\n",
    "    print(f\"\\n9. NEXT STEPS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Recommended next steps for data processing:\")\n",
    "    print(\"1. Text preprocessing and cleaning\")\n",
    "    print(\"2. Feature engineering (TF-IDF, word embeddings)\")\n",
    "    print(\"3. Sentiment analysis model training\")\n",
    "    print(\"4. Model evaluation and validation\")\n",
    "    print(\"5. Results interpretation and business insights\")\n",
    "    \n",
    "    return {\n",
    "        'total_records': len(df),\n",
    "        'missing_values': missing_count,\n",
    "        'duplicates': duplicate_count,\n",
    "        'inconsistencies': inconsistencies,\n",
    "        'avg_rating': df['rating'].mean(),\n",
    "        'avg_length': df['review_length'].mean(),\n",
    "        'outliers': review_length_outliers + word_count_outliers\n",
    "    }\n",
    "\n",
    "# Generate the summary\n",
    "summary_stats = generate_eda_summary()\n",
    "\n",
    "# 10. FINAL SUMMARY\n",
    "print(f\"\\n10. FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"EDA telah selesai dengan hasil sebagai berikut:\")\n",
    "print(f\"âœ“ Dataset berisi {summary_stats['total_records']} review\")\n",
    "print(f\"âœ“ Rata-rata rating: {summary_stats['avg_rating']:.2f}\")\n",
    "print(f\"âœ“ Rata-rata panjang review: {summary_stats['avg_length']:.1f} karakter\")\n",
    "print(f\"âœ“ Missing values: {summary_stats['missing_values']}\")\n",
    "print(f\"âœ“ Duplicates: {summary_stats['duplicates']}\")\n",
    "print(f\"âœ“ Inconsistencies: {summary_stats['inconsistencies']}\")\n",
    "print(f\"âœ“ Outliers: {summary_stats['outliers']}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Data siap untuk tahap preprocessing dan analisis lebih lanjut!\")\n",
    "print(f\"ðŸ“Š EDA Report generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Save summary to file\n",
    "with open('eda_summary_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# EDA Summary Report - redBus Reviews\\n\\n\")\n",
    "    f.write(f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"## Dataset Overview\\n\")\n",
    "    f.write(f\"- Total Records: {summary_stats['total_records']}\\n\")\n",
    "    f.write(f\"- Average Rating: {summary_stats['avg_rating']:.2f}\\n\")\n",
    "    f.write(f\"- Average Review Length: {summary_stats['avg_length']:.1f} characters\\n\\n\")\n",
    "    f.write(\"## Data Quality\\n\")\n",
    "    f.write(f\"- Missing Values: {summary_stats['missing_values']}\\n\")\n",
    "    f.write(f\"- Duplicates: {summary_stats['duplicates']}\\n\")\n",
    "    f.write(f\"- Inconsistencies: {summary_stats['inconsistencies']}\\n\")\n",
    "    f.write(f\"- Outliers: {summary_stats['outliers']}\\n\\n\")\n",
    "    f.write(\"## Status\\n\")\n",
    "    f.write(\"âœ… EDA Complete - Ready for Data Preprocessing\\n\")\n",
    "\n",
    "print(f\"\\nðŸ“„ Summary report saved to: eda_summary_report.md\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
